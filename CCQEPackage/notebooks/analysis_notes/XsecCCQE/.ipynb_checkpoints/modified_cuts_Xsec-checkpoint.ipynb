{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single differential $CC1p$ cross-section from begining to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versions:\n",
      "{   'OffBeam': 'prod_reco_optfilter_extbnb_v12_mcc8_dev',\n",
      "    'OnBeam': 'prod_reco_optfilter_bnb_v12_unblind_mcc8',\n",
      "    'Overlay': 'prodgenie_bnb_nu_uboone_overlay_mcc8.11_reco2',\n",
      "    'data date': '2018_05_11',\n",
      "    'date': '2018_05_11',\n",
      "    'overlay date': '2018_05_11'}\n",
      "OffBeam_scaling: 0.706302660161 = N(on beam)/N(off beam) before SwT\n",
      "f(POT): 0.0512441465374 = N(POT on beam)/N(POT MC)\n"
     ]
    }
   ],
   "source": [
    "from Xsec_setup import *\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figures_path = '/Users/erezcohen/Desktop/Projects/uBoone/write-ups/Xsec/Figures/1d_differential_Xsec/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load mc and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not find selected_cosmic_delta_theta_12_50.csv, so creating it...\n",
      "285009 ccqe candidate pairs, 180070 in FV\n",
      "74387 are 1mu-1p, 41.3%\n",
      "55226 are other pairs, 30.7%\n",
      "155396 are cosmic, 86.3%\n",
      "\u001b[92m--------------------------------------------------------------\u001b[0m\n",
      "36843 are CC 1p 0pi, 20.5%\n",
      "\u001b[92m--------------------------------------------------------------\u001b[0m\n",
      "40729 are CC 1p, 22.6%\n",
      "I finished loading overlay samples. We have in total 285009 pairs\n",
      "applied cuts to overlay\n",
      "saved selected 1mu-1p to /Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/selected_events/prodgenie_bnb_nu_uboone_overlay_mcc8.11_reco2_2018_08_16_selected_1mu-1p_delta_theta_12_50.csv\n",
      "saved selected other pairs to /Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/selected_events/prodgenie_bnb_nu_uboone_overlay_mcc8.11_reco2_2018_08_16_selected_other pairs_delta_theta_12_50.csv\n",
      "saved selected cosmic to /Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/selected_events/prodgenie_bnb_nu_uboone_overlay_mcc8.11_reco2_2018_08_16_selected_cosmic_delta_theta_12_50.csv\n",
      "saved selected CC 1p 0pi to /Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/selected_events/prodgenie_bnb_nu_uboone_overlay_mcc8.11_reco2_2018_08_16_selected_CC 1p 0pi_delta_theta_12_50.csv\n",
      "saved selected CC 1p to /Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/selected_events/prodgenie_bnb_nu_uboone_overlay_mcc8.11_reco2_2018_08_16_selected_CC 1p_delta_theta_12_50.csv\n",
      "Nevents['f(POT)']: 0.0510231354989\n",
      "13358 events in the overlay\n",
      "checked /Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/selected_events/prodgenie_bnb_nu_uboone_overlay_mcc8.11_reco2_2018_08_16_selected_on_beam_delta_theta_12_50.csv and there was no file there...\n",
      "loaded beam-on\n",
      "loaded beam-off\n",
      "applied cuts to data\n",
      "saved selected beam on to /Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/selected_events/prod_reco_optfilter_bnb_v12_unblind_mcc8_2018_08_16_selected_beam_on_delta_theta_12_50.csv\n",
      "saved selected beam on to /Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/selected_events/prod_reco_optfilter_bnb_v12_unblind_mcc8_2018_08_16_selected_beam_off_delta_theta_12_50.csv\n",
      "454 events in the beam-on\n",
      "17 events in the beam-off\n",
      "930168 events in genie\n",
      "saved genie_CC1p to /Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/selected_events/prodgenie_bnb_nu_uboone_overlay_mcc8.11_reco2_2018_08_16_selected_genie_CC1p_delta_theta_12_50.csv\n",
      "128622 CC1p events in genie\n",
      "10743 selected CC1p events overlay\n"
     ]
    }
   ],
   "source": [
    "versions['overlay date'] = '2018_08_16'\n",
    "versions['Overlay'] = 'prodgenie_bnb_nu_uboone_overlay_mcc8.11_reco2'\n",
    "selected_path = '/Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/selected_events/'\n",
    "prefix = selected_path + versions['Overlay'] + '_' + versions['overlay date'] + '_'\n",
    "selected_cosmic_filename = 'selected_cosmic'+modified_cut_name+'.csv'\n",
    "selected_overlay=dict()\n",
    "\n",
    "\n",
    "if os.path.isfile(prefix+selected_cosmic_filename): \n",
    "    print 'found '+selected_cosmic_filename+', loading it...'\n",
    "    for pair_type in pair_types:\n",
    "        selected_overlay[pair_type]=pd.read_csv(prefix+'selected_'+pair_type+'.csv')\n",
    "else:\n",
    "    print 'did not find '+selected_cosmic_filename+', so creating it...'\n",
    "    OverlaySamples = load_samples(date=versions['overlay date'],filename=versions['Overlay']+'_'+versions['overlay date']+'_vertices')\n",
    "    reducedOverlay,pureffOverlay,pureffNumbers = apply_cuts_to_overlay(OverlaySamples=OverlaySamples, cuts_order=cuts_order\n",
    "                                                                       ,minPEcut = minPEcut  \n",
    "                                                                       ,maxdYZcut = maxdYZcut\n",
    "                                                                       ,delta_theta_12 = delta_theta_12\n",
    "                                                                       ,r_max_RdQ_CC1p = r_max_RdQ_CC1p\n",
    "                                                                       ,delta_Delta_phi=delta_Delta_phi\n",
    "                                                                       ,Pt_max=Pt_max\n",
    "                                                                       ,Chi2Proton_muCandidate_min=Chi2Proton_muCandidate_min\n",
    "                                                                       ,Chi2Proton_pCandidate_max=Chi2Proton_pCandidate_max)\n",
    "    print 'applied cuts to overlay'\n",
    "    for pair_type in pair_types:\n",
    "        selected_overlay[pair_type] = reducedOverlay['Pt & delta phi'][pair_type]\n",
    "        outcsvname = prefix+'selected_'+pair_type+modified_cut_name+'.csv'\n",
    "        selected_overlay[pair_type].to_csv(outcsvname)\n",
    "        print 'saved selected',pair_type,'to',outcsvname    \n",
    "    # overlay scaling\n",
    "    summary = pd.read_csv('/Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/summary/'+versions['overlay date']+'/'+versions['Overlay']+'_'+versions['overlay date']+'_summary.csv')\n",
    "    Nevents['OnBeam POT'] = 4.908e+19\n",
    "    Nevents['overlay']      = np.sum(summary.Nevents)\n",
    "    Nevents['overlay POT']  = np.sum(summary.POT)\n",
    "    Nevents['f(POT)']       = Nevents['OnBeam POT']/Nevents['overlay POT']\n",
    "    print \"Nevents['f(POT)']:\",Nevents['f(POT)']\n",
    "selected_overlay_concat = pd.concat([selected_overlay['1mu-1p'],selected_overlay['cosmic'],selected_overlay['other pairs']])    \n",
    "print len(selected_overlay_concat),'events in the overlay'\n",
    "\n",
    "\n",
    "versions['data date'] = '2018_08_16'\n",
    "versions['beam on'] = 'prod_reco_optfilter_bnb_v12_unblind_mcc8'\n",
    "versions['beam off'] = 'prod_reco_optfilter_extbnb_v12_mcc8_dev'\n",
    "data_prefix = selected_path + versions['beam on'] + '_' + versions['data date'] + '_'\n",
    "if os.path.isfile(data_prefix+'selected_beam_on'+modified_cut_name+'.csv'):\n",
    "    print 'checked',data_prefix+'selected_on_beam'+modified_cut_name+'.csv and found the file...'\n",
    "    selected_beam_on = pd.read_csv(data_prefix+'selected_beam_on'+modified_cut_name+'.csv')\n",
    "    selected_beam_off = pd.read_csv(data_prefix+'selected_beam_off'+modified_cut_name+'.csv')\n",
    "\n",
    "else:\n",
    "    print 'checked',prefix+'selected_on_beam'+modified_cut_name+'.csv and there was no file there...'\n",
    "    OnBeam = pd.read_csv(vertices_files_path+'/'+versions['data date']+'/'+versions['beam on']+'_'+versions['data date']+'_vertices.csv')\n",
    "    print 'loaded beam-on'\n",
    "    OffBeam = pd.read_csv(vertices_files_path+'/'+versions['data date']+'/'+versions['beam off']+'_'+versions['data date']+'_vertices.csv')\n",
    "    print 'loaded beam-off'\n",
    "    reducedOnBeam,reducedOffBeam,numbers = apply_cuts_to_data(OnBeam=OnBeam,OffBeam=OffBeam,cuts_order=cuts_order\n",
    "                                                              ,minPEcut = minPEcut  \n",
    "                                                              ,maxdYZcut = maxdYZcut                                                              \n",
    "                                                              ,delta_theta_12 = delta_theta_12                                                              \n",
    "                                                              ,r_max_RdQ_CC1p = r_max_RdQ_CC1p\n",
    "                                                              ,delta_Delta_phi=delta_Delta_phi                                                              \n",
    "                                                              ,Pt_max=Pt_max                                                              \n",
    "                                                              ,Chi2Proton_muCandidate_min=Chi2Proton_muCandidate_min                                                              \n",
    "                                                              ,Chi2Proton_pCandidate_max=Chi2Proton_pCandidate_max)\n",
    "    print 'applied cuts to data'\n",
    "    selected_beam_on = reducedOnBeam['Pt & delta phi']\n",
    "    outcsvname = data_prefix+'selected_beam_on'+modified_cut_name+'.csv'\n",
    "    selected_beam_on.to_csv(outcsvname)\n",
    "    print 'saved selected beam on to',outcsvname\n",
    "\n",
    "    selected_beam_off = reducedOffBeam['Pt & delta phi']\n",
    "    outcsvname = data_prefix+'selected_beam_off'+modified_cut_name+'.csv'\n",
    "    selected_beam_off.to_csv(outcsvname)\n",
    "    print 'saved selected beam on to',outcsvname\n",
    "    \n",
    "print len(selected_beam_on),'events in the beam-on'\n",
    "print len(selected_beam_off),'events in the beam-off'\n",
    "\n",
    "\n",
    "if os.path.isfile(prefix+'selected_genie_CC1p'+modified_cut_name+'.csv'):\n",
    "    print 'checked',prefix+'selected_genie_CC1p'+modified_cut_name+'.csv and found the file...'\n",
    "    genie_CC1p = pd.read_csv(prefix+'selected_genie_CC1p'+modified_cut_name+'.csv')\n",
    "else:\n",
    "    genie = pd.read_csv('/Users/erezcohen/Desktop/uBoone/CCQEanalysis/csvFiles/genie/'\n",
    "                        +versions['overlay date']+'/'\n",
    "                        +versions['Overlay']+'_'+versions['overlay date']+'_genie.csv')\n",
    "    print len(genie),'events in genie'\n",
    "    genie_CC1p = genie[(genie.IsCC_1p_200MeVc==True) #& (genie.IsInActiveVolume==True) \n",
    "                       & ((genie.truth_x>3) & (genie.truth_x<256))\n",
    "                       & ((genie.truth_y>-115) & (genie.truth_y<115))\n",
    "                       & ((genie.truth_z>5) & (genie.truth_y<1037))\n",
    "                      ]\n",
    "    outcsvname = prefix+'selected_genie_CC1p'+modified_cut_name+'.csv'\n",
    "    genie_CC1p.to_csv(outcsvname)\n",
    "    print 'saved genie_CC1p to',outcsvname\n",
    "    print len(genie_CC1p),'CC1p events in genie'    \n",
    "selected_CC1p = selected_overlay['CC 1p']\n",
    "print len(selected_CC1p),'selected CC1p events overlay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eff(Ngen=1,Nsel=1,debug=0):\n",
    "    '''\n",
    "    return: eff, eff_err    \n",
    "    '''\n",
    "    eff = float(Nsel)/Ngen\n",
    "    eff_err = eff*np.sqrt(1./Nsel + 1./Ngen)\n",
    "    if debug: print 'eff = %.4f +/ %.4f'%(eff,eff_err)\n",
    "    return eff,eff_err\n",
    "\n",
    "def get_eff_samples(generated=None,selected=None,debug=0):\n",
    "    '''\n",
    "    return: eff, eff_err    \n",
    "    '''\n",
    "    Ngen = float(len(generated))\n",
    "    Nsel = float(len(selected))\n",
    "    return get_eff(Ngen=Ngen,Nsel=Nsel,debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smear_MC(in_sample=None,migration_maps=None,debug=0,name='smeared_mc_tmp'):\n",
    "    sam = in_sample\n",
    "    debug=0\n",
    "    smeared_Pmu_array,smeared_Pmu_theta_array,smeared_Pp_array,smeared_Pp_theta_array = [],[],[],[]\n",
    "    smeared_Pmu_cos_theta_array,smeared_Pp_cos_theta_array=[],[]\n",
    "    for i,row in sam.iterrows():\n",
    "\n",
    "        # smearing p(muon)\n",
    "        true_bin_j = find_bin(row['truth_Pmu'], Bins['Pmu'])\n",
    "        smeared_Pmu_array.append(choice(a=0.5*(Bins['Pmu'][1:]+Bins['Pmu'][:-1]) , p=migration_maps['Pmu'][:,true_bin_j]))\n",
    "        # smearing theta(muon)\n",
    "        true_bin_j = find_bin(180./np.pi*row['truth_Pmu_theta'], Bins['theta(mu)'])\n",
    "        smeared_Pmu_theta_array.append(np.pi/180.*choice(a=0.5*(Bins['theta(mu)'][1:]+Bins['theta(mu)'][:-1]) , p=migration_maps['Pmu_theta'][:,true_bin_j]))\n",
    "        # smearing cos(theta(muon))\n",
    "        true_bin_j = find_bin(row['truth_Pmu_cos_theta'], Bins['cos(theta(mu))'])\n",
    "        smeared_Pmu_cos_theta_array.append(choice(a=0.5*(Bins['cos(theta(mu))'][1:]+Bins['cos(theta(mu))'][:-1]) , p=migration_maps['Pmu_cos_theta'][:,true_bin_j]))\n",
    "        # smearing p(proton)\n",
    "        true_bin_j = find_bin(row['truth_Pp'], Bins['Pp'])\n",
    "        smeared_Pp_array.append(choice(a=0.5*(Bins['Pp'][1:]+Bins['Pp'][:-1]) , p=migration_maps['Pp'][:,true_bin_j]))\n",
    "        # smearing theta(proton)\n",
    "        true_bin_j = find_bin(180./np.pi*row['truth_Pp_theta'], Bins['theta(p)'])\n",
    "        smeared_Pp_theta_array.append(np.pi/180.*choice(a=0.5*(Bins['theta(p)'][1:]+Bins['theta(p)'][:-1]) , p=migration_maps['Pp_theta'][:,true_bin_j]))\n",
    "        # smearing cos(theta(p))\n",
    "        true_bin_j = find_bin(row['truth_Pp_cos_theta'], Bins['cos(theta(p))'])\n",
    "        smeared_Pp_cos_theta_array.append(choice(a=0.5*(Bins['cos(theta(p))'][1:]+Bins['cos(theta(p))'][:-1]) , p=migration_maps['Pp_cos_theta'][:,true_bin_j]))\n",
    "\n",
    "\n",
    "        if debug:\n",
    "            print 'truth_Pmu:',row['truth_Pmu']\n",
    "            print 'smeared_Pmu:',choice(a=0.5*(Bins['Pmu'][1:]+Bins['Pmu'][:-1]) , p=migration_map[:,find_bin(row['truth_Pmu'], Bins['Pmu'])])        \n",
    "            print 'truth_Pp_theta:',row['truth_Pp_theta']\n",
    "            print 'true_bin_j:',true_bin_j\n",
    "            print 'smeared_Pp_theta:',choice(a=0.5*(Bins['theta(p)'][1:]+Bins['theta(p)'][:-1]) , p=migration_map[:,true_bin_j])\n",
    "            print 'smeared_Pp_theta:',np.pi/180.*choice(a=0.5*(Bins['theta(p)'][1:]+Bins['theta(p)'][:-1]) , p=migration_map[:,true_bin_j])\n",
    "            print_line()\n",
    "    if debug:\n",
    "        print 'done looping.'\n",
    "    sam['smeared_Pmu']=smeared_Pmu_array\n",
    "    sam['smeared_Pmu_theta']=smeared_Pmu_theta_array\n",
    "    sam['smeared_Pmu_cos_theta']=smeared_Pmu_cos_theta_array\n",
    "    sam['smeared_Pp']=smeared_Pp_array\n",
    "    sam['smeared_Pp_theta']=smeared_Pp_theta_array\n",
    "    sam['smeared_Pp_cos_theta']=smeared_Pp_cos_theta_array\n",
    "    if debug:\n",
    "        print 'done smearing',name\n",
    "    sam.to_csv(prefix + name +modified_cut_name+'.csv')\n",
    "    if debug:\n",
    "        print 'saved ',name,' to\\n',(prefix + name + '.csv')\n",
    "    return sam     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_migration_map(sam=None,bins=None,xvar='',yvar='',mul=1,debug=0):\n",
    "    xbins = ybins = bins*(1./mul)\n",
    "    nbins = len(bins)-1\n",
    "    migration_map = np.zeros((nbins,nbins))\n",
    "    for ix in range(nbins):\n",
    "        xmin,xmax = xbins[ix],xbins[ix+1]  \n",
    "        sum_in_column = 0\n",
    "        for iy in range(nbins):\n",
    "            ymin,ymax = ybins[iy],ybins[iy+1]\n",
    "            sam_bin = sam[(sam[xvar]>xmin)&(sam[xvar]<xmax)&(sam[yvar]>ymin)&(sam[yvar]<ymax)]\n",
    "            migration_map[ix][iy] = float(len(sam_bin))\n",
    "            sum_in_column += migration_map[ix][iy]        \n",
    "        # now normalize the entire column to 1\n",
    "        for iy in range(nbins):\n",
    "            migration_map[ix][iy] /= sum_in_column\n",
    "    migration_map=migration_map.T\n",
    "    if debug:\n",
    "        print 'done computing migration matrix'\n",
    "        fig,ax = plt.subplots(figsize=(9.708,6))\n",
    "        sns.heatmap(migration_map,annot=True,fmt=\".2f\",cbar=False,cmap='jet')\n",
    "        set_axes(ax,'True bin $j$','Reconstructed bin $i$')\n",
    "        ax.invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        filename = Paths['migration maps'] + '%s_vs_%s_%d_bins'%(xvar,yvar,nbins)+modified_cut_name+'.csv'\n",
    "        np.savetxt(filename, migration_map, delimiter=\",\")\n",
    "        print 'saved migration map into',filename\n",
    "        print 'done building migration maps'\n",
    "    return migration_map   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_effiency(bins=Bins['Pmu']\n",
    "                     ,xvar='smeared_Pmu'\n",
    "                     ,xlabel='p_{\\mu}'\n",
    "                     ,ylabel=r'$\\bar{\\epsilon}$'\n",
    "                     ,do_draw=True\n",
    "                     ,mul=1\n",
    "                     ,debug=0\n",
    "                    ):\n",
    "    mid = 0.5*(bins[1:]+bins[:-1]); bin_width=0.5*(mid[1]-mid[0])\n",
    "    h = dict()\n",
    "    h['generated'],_ = np.histogram(mul*genie_CC1p[xvar],bins=bins)\n",
    "    h['selected'],_ = np.histogram(mul*selected_CC1p[xvar],bins=bins)\n",
    "\n",
    "    h['eff'],h['eff err'] = [],[]\n",
    "    for i in range(len(bins)-1):\n",
    "        eff,eff_err = get_eff(Ngen=h['generated'][i],Nsel=h['selected'][i])\n",
    "        h['eff'].append(eff)\n",
    "        h['eff err'].append(eff_err)\n",
    "    if debug: print 'done computing efficiency.'\n",
    "    \n",
    "    if do_draw and debug:\n",
    "        fig=plt.figure(figsize=(20,6))\n",
    "        ax=fig.add_subplot(1,2,1)\n",
    "        for label,color in zip(['generated','selected'],['forestgreen','royalblue']):\n",
    "            plt.errorbar(x=mid,xerr=bin_width,y=h[label],yerr=np.sqrt(h[label])\n",
    "                         ,color=color,capsize=10,fmt='.',markersize=0,label=label)\n",
    "        set_axes(ax,xlabel,'counts',do_add_grid=True,do_add_legend=True)\n",
    "\n",
    "        ax=fig.add_subplot(1,2,2)\n",
    "        plt.errorbar(x=mid,xerr=bin_width,y=h['eff'],yerr=h['eff err']\n",
    "                         ,color='black',capsize=10,fmt='.',markersize=0)\n",
    "        set_axes(ax,xlabel,ylabel,do_add_grid=True,ylim=(0,1.05*np.max(h['eff']+h['eff err'])))\n",
    "    if debug: print 'done drawing.'\n",
    "    \n",
    "    # save to csv\n",
    "    np.savetxt(Paths['efficiency maps'] + \"eff_%s_%d_bins\"%(xvar,len(bins)-1)+modified_cut_name+\".csv\", h['eff'], delimiter=\",\")\n",
    "    np.savetxt(Paths['efficiency maps'] + \"eff_err_%s_%d_bins\"%(xvar,len(bins)-1)+modified_cut_name+\".csv\", h['eff err'], delimiter=\",\")\n",
    "    if debug:  print 'saved efficiency into',Paths['efficiency maps'] + \"eff_%s_%d_bins\"%(xvar,len(bins)-1)+modified_cut_name+\".csv\",'\\n and uncertainty'\n",
    "    return h['eff'],h['eff err']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bin( x , bins ):    \n",
    "    for i in range(len(bins)-1):\n",
    "        if bins[i]<x and x<bins[i+1]:\n",
    "            return i\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_migration_maps():\n",
    "    migration_maps=dict()\n",
    "    migration_maps['Pmu']=build_migration_map(sam=selected_CC1p,bins=Bins['Pmu'],xvar='truth_Pmu',yvar='reco_Pmu_mcs')\n",
    "    migration_maps['Pp']=build_migration_map(sam=selected_CC1p,bins=Bins['Pp'],xvar='truth_Pp',yvar='reco_Pp')\n",
    "    migration_maps['Pmu_theta']=build_migration_map(sam=selected_CC1p,bins=Bins['theta(mu)'],xvar='truth_Pmu_theta',yvar='reco_Pmu_mcs_theta',mul=180./np.pi)\n",
    "    migration_maps['Pp_theta']=build_migration_map(sam=selected_CC1p,bins=Bins['theta(p)'],xvar='truth_Pp_theta',yvar='reco_Pp_theta',mul=180./np.pi)\n",
    "    migration_maps['Pmu_cos_theta']=build_migration_map(sam=selected_CC1p,bins=Bins['cos(theta(mu))'],xvar='truth_Pmu_cos_theta',yvar='reco_Pmu_cos_theta')\n",
    "    migration_maps['Pp_cos_theta']=build_migration_map(sam=selected_CC1p,bins=Bins['cos(theta(p))'],xvar='truth_Pp_cos_theta',yvar='reco_Pp_cos_theta')\n",
    "    return migration_maps\n",
    "\n",
    "def smear_MC_gen_sel(migration_maps=None):\n",
    "    smear_MC(in_sample=selected_CC1p,migration_maps=migration_maps,name='selected_CC 1p')\n",
    "    smear_MC(in_sample=genie_CC1p,migration_maps=migration_maps,name='selected_genie_CC1p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtrsact_bkg_1d(bins=Bins['Pmu'],xlabel='',xvar='reco_Pmu_mcs',mul=1,debug=0):\n",
    "    mid = 0.5*(bins[1:]+bins[:-1]); bin_width=0.5*(mid[1]-mid[0])\n",
    "    h,herr = dict(),dict()\n",
    "    \n",
    "    # data\n",
    "    for sam,label in zip([selected_beam_off,selected_beam_on],['beam off','beam on']):\n",
    "        h[label],_ = np.histogram( mul*sam[xvar] , bins=bins )\n",
    "        herr[label] = np.sqrt(h[label])\n",
    "    # scale beam-off to beam-on exposure time\n",
    "    h['beam off'] = h['beam off']*OffBeam_scaling\n",
    "    herr['beam off'] = h['beam off']*OffBeam_scaling\n",
    "    \n",
    "    # MC\n",
    "    for sam,label in zip([selected_overlay_concat,selected_overlay['CC 1p']],['overlay','CC 1p']):\n",
    "        h[label],_ = np.histogram( mul*sam[xvar] , bins=bins )\n",
    "        h[label] = h[label]*Nevents['f(POT)']\n",
    "        herr[label] = np.sqrt(h[label])*Nevents['f(POT)']\n",
    "\n",
    "    h['ovrelay + beam off'] = h['overlay'] + h['beam off']\n",
    "    herr['overlay + beam off'] = np.sqrt(np.square(herr['overlay']) + np.square(herr['beam off']))\n",
    "    h['background'] = h['ovrelay + beam off'] - h['CC 1p']\n",
    "    herr['background'] = np.sqrt(np.square(herr['overlay + beam off']) + np.square(herr['CC 1p']))\n",
    "    h['beam on bkg subtracted'] = h['beam on'] - h['background']\n",
    "    herr['beam on bkg subtracted'] = np.sqrt(np.square(herr['beam on']) + np.square(herr['background']))\n",
    "\n",
    "    if debug:\n",
    "        fig = plt.figure(figsize=(20,6))\n",
    "        ax=fig.add_subplot(1,2,1)\n",
    "        ax.bar( mid , h['overlay']+h['beam off'] , width=2*bin_width , color=Colors['beam off'], label='beam-off',alpha=0.7)\n",
    "        ax.bar( mid , h['overlay'] , width=2*bin_width, color=Colors['overlay'], label='overlay',alpha=0.7)\n",
    "        ax.bar( mid , h['CC 1p'], width=2*bin_width, color=Colors['CC 1p'], label=r'CC 1p signal')\n",
    "        ax.errorbar( x=mid , xerr=bin_width, y=h['beam on'], yerr=herr['beam on'] , fmt='o', markersize=10 \n",
    "                    , color=Colors['beam on'], capsize=1, capthick=3, label='beam-on')\n",
    "        set_axes(ax,xlabel,do_add_legend=True)\n",
    "        ylim = ax.get_ylim()\n",
    "\n",
    "        ax=fig.add_subplot(1,2,2)\n",
    "        ax.bar( mid , h['CC 1p'], width=2*bin_width, color=Colors['CC 1p'])\n",
    "        ax.errorbar( x=mid , xerr=bin_width, y=h['beam on bkg subtracted'], yerr=herr['beam on bkg subtracted'] , fmt='o', markersize=10 \n",
    "                    , color=Colors['beam on'], capsize=1, capthick=3, label='beam-on')\n",
    "        set_axes(ax,xlabel,do_add_legend=True,ylim=ylim)   \n",
    "    \n",
    "    np.savetxt(Paths['background maps'] + \"beam_on_bkg_sbtrctd_%s_%d_bins\"%(xvar,len(bins)-1)+modified_cut_name+\".csv\", h['beam on bkg subtracted'], delimiter=\",\")\n",
    "    np.savetxt(Paths['background maps'] + \"beam_on_bkg_sbtrctd_err_%s_%d_bins\"%(xvar,len(bins)-1)+modified_cut_name+\".csv\", herr['beam on bkg subtracted'], delimiter=\",\")\n",
    "    if debug: print 'saved',\"beam_on_bkg_sbtrctd_%s_%d_bins.csv\"%(xvar,len(bins)-1)\n",
    "    \n",
    "    np.savetxt(Paths['background maps'] + \"mc_cc1p_%s_%d_bins\"%(xvar,len(bins)-1)+modified_cut_name+\".csv\", h['CC 1p'], delimiter=\",\")\n",
    "    np.savetxt(Paths['background maps'] + \"mc_cc1p_err_%s_%d_bins\"%(xvar,len(bins)-1)+modified_cut_name+\".csv\", herr['CC 1p'], delimiter=\",\")\n",
    "    if debug: print 'saved',\"mc_cc1p_%s_%d_bins.csv\"%(xvar,len(bins)-1) \n",
    "    if debug: print 'done background subtraction from data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xsec_diff_1d(observable='Pmu',recovar='reco_Pmu_mcs',smearedvar='',debug=0,do_draw=True):\n",
    "    bins=Bins[observable]; vlabel=vlabels[observable]; Vlabel=Vlabels[observable]; units=Units[observable]\n",
    "    xlabel=Vlabel+' ['+units+']' if units is not None else Vlabel\n",
    "\n",
    "    if smearedvar is '': smearedvar='smeared_'+observable\n",
    "    mul=180./np.pi if 'theta' in observable else 1\n",
    "    mid = 0.5*(bins[1:]+bins[:-1]); bin_width=0.5*(mid[1]-mid[0])\n",
    "    \n",
    "    h,herr = dict(),dict()\n",
    "    h['N-B'] = np.loadtxt(Paths['background maps'] + \"beam_on_bkg_sbtrctd_%s_%d_bins\"%(recovar,len(bins)-1)+modified_cut_name+\".csv\", delimiter=\",\")\n",
    "    herr['N-B'] = np.loadtxt(Paths['background maps'] + \"beam_on_bkg_sbtrctd_err_%s_%d_bins\"%(recovar,len(bins)-1)+modified_cut_name+\".csv\", delimiter=\",\")\n",
    "    if debug: print 'read ', \"beam_on_bkg_sbtrctd_%s_%d_bins\"%(recovar,len(bins)-1)+modified_cut_name+\".csv\"\n",
    "\n",
    "    h['mc'] = np.loadtxt(Paths['background maps'] + \"mc_cc1p_%s_%d_bins\"%(recovar,len(bins)-1)+modified_cut_name+\".csv\", delimiter=\",\")\n",
    "    herr['mc'] = np.loadtxt(Paths['background maps'] + \"mc_cc1p_err_%s_%d_bins\"%(recovar,len(bins)-1)+modified_cut_name+\".csv\", delimiter=\",\")\n",
    "    if debug: print 'read ',\"mc_cc1p_%s_%d_bins\"%(recovar,len(bins)-1)+modified_cut_name+\".csv\"\n",
    "    \n",
    "    h['eff'] = np.loadtxt(Paths['efficiency maps'] + \"eff_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\", delimiter=\",\")\n",
    "    herr['eff'] = np.loadtxt(Paths['efficiency maps'] + \"eff_err_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\", delimiter=\",\")\n",
    "    if debug: print 'read efficiency',\"eff_%s_%d_bins\"%(recovar,len(bins)-1)+modified_cut_name+\".csv\"\n",
    "    \n",
    "    h['Xsec'] = h['N-B']/(h['eff']*Ntargets*flux*bin_width)\n",
    "    herr['Xsec'] = np.sqrt( np.square(herr['N-B']/(h['eff']*Ntargets*flux*bin_width))\n",
    "                            +np.square(h['N-B']*herr['eff']/(h['eff']*h['eff']*Ntargets*flux*bin_width))                           \n",
    "                            +np.square(h['N-B']*Ntargets_err/(h['eff']*Ntargets*Ntargets*flux*bin_width))\n",
    "                            +np.square(h['N-B']*flux_err/(h['eff']*Ntargets*flux*flux*bin_width)))\n",
    "    h['Xsec'],herr['Xsec'] = h['Xsec']*1e39,herr['Xsec']*1e39\n",
    "    \n",
    "    h['mc'] = h['mc']/(h['eff']*Ntargets*flux*bin_width)\n",
    "    herr['mc'] = np.sqrt( np.square(herr['mc']/(h['eff']*Ntargets*flux*bin_width))\n",
    "                            +np.square(h['mc']*herr['eff']/(h['eff']*h['eff']*Ntargets*flux*bin_width))                           \n",
    "                            +np.square(h['mc']*Ntargets_err/(h['eff']*Ntargets*Ntargets*flux*bin_width))\n",
    "                            +np.square(h['mc']*flux_err/(h['eff']*Ntargets*flux*flux*bin_width)))\n",
    "    h['mc'],herr['mc'] = h['mc']*1e39,herr['mc']*1e39\n",
    "\n",
    "\n",
    "    if do_draw:\n",
    "        fig = plt.figure(figsize=(9.708,6))\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        ax.bar( x=mid , height=2*herr['mc'], bottom=h['mc']-herr['mc'], width=2*bin_width, color=Colors['CC 1p'], label=r'mc ($\\Delta$stat.)')\n",
    "        ax.errorbar( x=mid , xerr=bin_width, y=h['Xsec'], yerr=herr['Xsec'] , fmt='o', markersize=10 \n",
    "                    , color=Colors['beam on'], capsize=1, capthick=3, label='data')    \n",
    "        set_axes(ax,xlabel\n",
    "                 ,y_label=r'$\\frac{d\\sigma}{d'+vlabel+'}$'+r' $\\left[10^{-39} \\frac{cm^{2}}{(%s)}\\right]$'%units\n",
    "                 ,do_add_legend=True)\n",
    "    \n",
    "    np.savetxt(Paths['1d Xsec'] + \"Xsec_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\", h['Xsec'], delimiter=\",\")\n",
    "    np.savetxt(Paths['1d Xsec'] + \"Xec_err_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\", herr['Xsec'], delimiter=\",\")\n",
    "    if debug: print 'saved',\"Xsec_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\"\n",
    "\n",
    "    np.savetxt(Paths['1d Xsec'] + \"mc_cc1p_Xsec_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\", h['mc'], delimiter=\",\")\n",
    "    np.savetxt(Paths['1d Xsec'] + \"mc_cc1p_Xsec_err_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\", herr['mc'], delimiter=\",\")\n",
    "    if debug: print 'saved',\"mc_cc1p_Xsec_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\"\n",
    "    print 'done computing Xsec.'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xsec_ratio_1d(observable='Pmu',recovar='reco_Pmu_mcs',smearedvar='',debug=0,ax=None):\n",
    "    bins=Bins[observable]; vlabel=vlabels[observable]; Vlabel=Vlabels[observable]; units=Units[observable]\n",
    "    xlabel=Vlabel+' ['+units+']' if units is not None else Vlabel\n",
    "    mid = 0.5*(bins[1:]+bins[:-1]); bin_width=0.5*(mid[1]-mid[0])\n",
    "    \n",
    "    h,herr = dict(),dict()\n",
    "    \n",
    "    h['nominal Xsec'] = np.loadtxt(Paths['1d Xsec'] + \"Xsec_%s_%d_bins.csv\"%(smearedvar,len(bins)-1), delimiter=\",\")\n",
    "    herr['nominal Xsec'] = np.loadtxt(Paths['1d Xsec'] + \"Xec_err_%s_%d_bins.csv\"%(smearedvar,len(bins)-1), delimiter=\",\")\n",
    "    if debug: print 'read',\"Xsec_%s_%d_bins.csv\"%(smearedvar,len(bins)-1)\n",
    "    h['modified Xsec'] = np.loadtxt(Paths['1d Xsec'] + \"Xsec_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\", delimiter=\",\")\n",
    "    herr['modified Xsec'] = np.loadtxt(Paths['1d Xsec'] + \"Xec_err_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\", delimiter=\",\")\n",
    "    if debug: print 'read',\"Xsec_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\"\n",
    "\n",
    "\n",
    "    h['nominal mc'] = np.loadtxt(Paths['1d Xsec'] + \"mc_cc1p_Xsec_%s_%d_bins.csv\"%(smearedvar,len(bins)-1), delimiter=\",\")\n",
    "    herr['nominal mc'] = np.loadtxt(Paths['1d Xsec'] + \"mc_cc1p_Xsec_err_%s_%d_bins.csv\"%(smearedvar,len(bins)-1), delimiter=\",\")\n",
    "    if debug: print 'read',\"mc_cc1p_Xsec_%s_%d_bins.csv\"%(smearedvar,len(bins)-1)\n",
    "    h['modified mc'] = np.loadtxt(Paths['1d Xsec'] + \"mc_cc1p_Xsec_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\", delimiter=\",\")\n",
    "    herr['modified mc'] = np.loadtxt(Paths['1d Xsec'] + \"mc_cc1p_Xsec_err_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\", delimiter=\",\")\n",
    "    if debug: print 'read',\"mc_cc1p_Xsec_%s_%d_bins\"%(smearedvar,len(bins)-1)+modified_cut_name+\".csv\"\n",
    "\n",
    "    print 'done reading Xsec.'\n",
    "    if ax is None:\n",
    "        fig,ax = plt.subplots(figsize=(9.708,6))\n",
    "    for slabel,color in zip(['mc','Xsec'],[Colors['CC 1p'],Colors['beam on']]):\n",
    "        h['ratio '+slabel] = h['modified '+slabel]/h['nominal '+slabel]\n",
    "        herr['ratio '+slabel] = h['ratio '+slabel]*np.sqrt( np.square(herr['nominal '+slabel]/h['nominal '+slabel]) \n",
    "                                                           + np.square(herr['modified '+slabel]/h['modified '+slabel]) )\n",
    "        if debug:\n",
    "            print \"h[nominal \"+slabel+\"]:\",h['nominal '+slabel]\n",
    "            print \"herr[nominal \"+slabel+\"]:\",herr['nominal '+slabel]\n",
    "            print \"h[modified \"+slabel+\"]:\",h['modified '+slabel]\n",
    "            print \"herr[modified \"+slabel+\"]:\",herr['modified '+slabel]\n",
    "            print \"h[ratio \"+slabel+\"]:\",h['ratio '+slabel]\n",
    "            print \"herr[ratio \"+slabel+\"]:\",herr['ratio '+slabel]\n",
    "        ax.errorbar( x=mid , xerr=bin_width, y=h['ratio '+slabel], yerr=herr['ratio '+slabel] \n",
    "                    , fmt='o', markersize=10 , color=color, capsize=1, capthick=3, label='data')    \n",
    "    set_axes(ax,xlabel,y_label=r'Xsec. ratio',do_add_legend=False,title=modified_cut_label)    \n",
    "    print 'done ploting Xsec. ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_chain_Xsec_diff_1d(observable='Pmu',truth_var='truth_Pmu',recovar='reco_Pmu_mcs',smearedvar='',mul=1,ax=None):\n",
    "    bins=Bins[observable]; vlabel=vlabels[observable]; Vlabel=Vlabels[observable]; units=Units[observable]\n",
    "    xlabel=Vlabel+' ['+units+']' if units is not None else Vlabel\n",
    "\n",
    "    # (1) background subtraction    \n",
    "    subtrsact_bkg_1d(bins=bins,xlabel=xlabel,xvar=recovar,debug=0)\n",
    "    \n",
    "    # (2) efficiency:\n",
    "    compute_effiency(bins=bins,xvar=smearedvar,xlabel=xlabel,ylabel=r'$\\bar{\\epsilon}$',do_draw=True,mul=mul,debug=0)    \n",
    "    \n",
    "    # (3) cross-section\n",
    "    Xsec_diff_1d(observable=observable,recovar=recovar,smearedvar=smearedvar,debug=0,do_draw=False)\n",
    "    \n",
    "    # (4) ratio of cross-section to nominal Xsec\n",
    "    Xsec_ratio_1d(observable=observable,recovar=recovar,smearedvar=smearedvar,debug=0,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d cross-section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing Xsec. for _Chi2Proton_pCandidate_max_40\n"
     ]
    }
   ],
   "source": [
    "cuts_order  = ['no cut','Chi2Proton','Nflashes','MatchedFlash','length','non-collinearity','vertex activity','delta phi','Pt & delta phi']\n",
    "minPEcut = 150 \n",
    "maxdYZcut = 200 \n",
    "delta_theta_12 = 55 \n",
    "r_max_RdQ_CC1p = 0.43\n",
    "delta_Delta_phi=35 \n",
    "Pt_max=0.35        \n",
    "Chi2Proton_muCandidate_min=80 \n",
    "Chi2Proton_pCandidate_max=30 \n",
    "\n",
    "# modified_cut_name,modified_cut_label = '_minPEcut_200',r'$N_{PE} >$ 150 $ \\to $ 200'\n",
    "# minPEcut = 200\n",
    "# modified_cut_name,modified_cut_label = '_maxdYZcut_250',r'$d_{yz} <$ 200 cm$ \\to $ 250 cm'\n",
    "# maxdYZcut = 250\n",
    "# modified_cut_name,modified_cut_label = '_delta_theta_12_60',r'$35^0 < \\theta_{12} < 145^0$ $ \\to $ $30^0 < \\theta_{12} < 150^0$'\n",
    "# delta_theta_12 = 60\n",
    "# modified_cut_name,modified_cut_label = '_r_max_RdQ_CC1p_0.48',r'$r_{\\Delta Q} < 0.43$ $ \\to $ $0.48$'\n",
    "# r_max_RdQ_CC1p = 0.48\n",
    "# modified_cut_name,modified_cut_label = '_delta_Delta_phi_40',r'$145^0<\\Delta\\phi<215^0$ $ \\to $ $140^0<\\Delta\\phi<220^0$'\n",
    "# delta_Delta_phi = 40\n",
    "# modified_cut_name,modified_cut_label = '_Pt_max_0.4',r'$p_t < 0.35$ GeV/c $ \\to $ $0.4$ GeV/c'\n",
    "# Pt_max = 0.4\n",
    "modified_cut_name,modified_cut_label = '_Chi2Proton_pCandidate_max_40',r'$(\\chi^2_p)^p <$ 30 $ \\to $ 40'\n",
    "Chi2Proton_pCandidate_max = 40\n",
    "print 'computing Xsec. for',modified_cut_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_maps = build_migration_maps()\n",
    "smear_MC_gen_sel(migration_maps=migration_maps)\n",
    "print 'done smearing MC generated and selected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print prefix+'selected_genie_CC1p.csv'\n",
    "genie_CC1p = pd.read_csv(prefix+'selected_genie_CC1p'+modified_cut_name+'.csv')\n",
    "selected_CC1p = pd.read_csv(prefix+'selected_CC 1p'+modified_cut_name+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xsec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20,12))\n",
    "ax=fig.add_subplot(2,2,1)\n",
    "full_chain_Xsec_diff_1d(observable='Pmu',recovar='reco_Pmu_mcs',smearedvar='smeared_Pmu',ax=ax)\n",
    "ax=fig.add_subplot(2,2,2)\n",
    "full_chain_Xsec_diff_1d(observable='Pp',recovar='reco_Pp',smearedvar='smeared_Pp',ax=ax)\n",
    "ax=fig.add_subplot(2,2,3)\n",
    "full_chain_Xsec_diff_1d(observable='cos(theta(mu))',recovar='reco_Pmu_cos_theta',smearedvar='smeared_Pmu_cos_theta',ax=ax)\n",
    "ax=fig.add_subplot(2,2,4)\n",
    "full_chain_Xsec_diff_1d(observable='cos(theta(p))',recovar='reco_Pp_cos_theta',smearedvar='smeared_Pp_cos_theta',ax=ax)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
